#  Атаки на системы машинного обучения.

Вам предлагается выполнить серию практических заданий, каждое из которых посвящено конкретной атаке. Ваша задача — реализовать код для выполнения атаки, провести анализ последствий и предложить возможные способы защиты модели.

---

## Задание 1 и 2. Атаки adversarial на модель, реализация защитных механизмов 

Цель: Демонстрация уязвимости модели к атаке, демонстрация вариантов защиты модели от атак.

[Adversarial_Attack_Defence](https://github.com/goralex02/attacks_on_models/tree/main/Adversarial_Attack_Defence)

---

## Задание 3. Утечка данных через модель

Цель: Понять риски, связанные с утечкой данных.

[Membership_Inference_Attack](https://github.com/goralex02/attacks_on_models/tree/main/Membership_Inference_Attack)

---

## Задание 5. Защита от модели-имитатора (Model Stealing)

Цель: Проверка уязвимости модели классификации к краже.

[Model_stealing](https://github.com/goralex02/attacks_on_models/tree/main/Model_stealing)
