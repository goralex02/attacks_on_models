#  Атаки на системы машинного обучения.

---

## Задание 1. Атаки adversarial на модель 

Цель: Демонстрация уязвимости модели к атаке.

---

## Задание 2: Атаки adversarial на модель, реализация защитных механизмов 

Цель: Демонстрация вариантов защиты модели от атак.

---

## Задание 3. Утечка данных через модель

Цель: Понять риски, связанные с утечкой данных.

---

## Задание 4. «Отравленные» данные (Data Poisoning) 

Цель: Исследование влияния вредоносных данных на обучение модели.

---

## Задание 5. Защита от модели-имитатора (Model Stealing)

Цель: Проверка уязвимости модели классификации к краже.
